{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom xgboost import XGBRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-23T12:52:32.121316Z","iopub.execute_input":"2021-09-23T12:52:32.121743Z","iopub.status.idle":"2021-09-23T12:52:32.535322Z","shell.execute_reply.started":"2021-09-23T12:52:32.121631Z","shell.execute_reply":"2021-09-23T12:52:32.534366Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:52:32.537076Z","iopub.execute_input":"2021-09-23T12:52:32.537498Z","iopub.status.idle":"2021-09-23T12:52:36.299680Z","shell.execute_reply.started":"2021-09-23T12:52:32.537456Z","shell.execute_reply":"2021-09-23T12:52:36.298690Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:52:36.304567Z","iopub.execute_input":"2021-09-23T12:52:36.304964Z","iopub.status.idle":"2021-09-23T12:52:36.349438Z","shell.execute_reply.started":"2021-09-23T12:52:36.304922Z","shell.execute_reply":"2021-09-23T12:52:36.348468Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\ny_test_pred = []\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Scaling Features\n    scaler = preprocessing.StandardScaler()\n    X_train_f[num_col] = scaler.fit_transform(X_train_f[num_col])\n    X_valid_f[num_col] = scaler.transform(X_valid_f[num_col])\n    X_test[num_col] = scaler.transform(X_test[num_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:52:36.352430Z","iopub.execute_input":"2021-09-23T12:52:36.352829Z","iopub.status.idle":"2021-09-23T12:53:01.590854Z","shell.execute_reply.started":"2021-09-23T12:52:36.352790Z","shell.execute_reply":"2021-09-23T12:53:01.589849Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Converting list of list to arraywith column_stack\n#y_test_pred = np.mean(np.column_stack(y_test_pred), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:53:01.592219Z","iopub.execute_input":"2021-09-23T12:53:01.593211Z","iopub.status.idle":"2021-09-23T12:53:01.597479Z","shell.execute_reply.started":"2021-09-23T12:53:01.593173Z","shell.execute_reply":"2021-09-23T12:53:01.596317Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\n# Log tranformation\nfor col in num_col:\n    df_train[col] = np.log1p(df_train[col])\n    df_test[col] = np.log1p(df_test[col])\n\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:53:01.598938Z","iopub.execute_input":"2021-09-23T12:53:01.599905Z","iopub.status.idle":"2021-09-23T12:53:25.155154Z","shell.execute_reply.started":"2021-09-23T12:53:01.599866Z","shell.execute_reply":"2021-09-23T12:53:25.154194Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1).copy()\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\n# Polynomials\npoly = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n\ntrain_poly = poly.fit_transform(X_train[num_col])\nX_train_poly = pd.DataFrame(train_poly,\n                            columns=[f'poly_{i}' for i in range(train_poly.shape[1])],\n                            index=X_train.index) # using index for cancatenation\nX_train = pd.concat([X_train[cat_col],X_train_poly], axis=1) # To avoid duplicating, we just concat cat_col with poly dataframe\n\ntest_poly = poly.fit_transform(df_test[num_col])\ndf_test_poly = pd.DataFrame(test_poly,\n                            columns=[f'poly_{i}' for i in range(test_poly.shape[1])],\n                            index=X_test.index)\ndf_test = pd.concat([X_test[cat_col],df_test_poly], axis=1)\n\n\n# KFold\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:53:28.615453Z","iopub.execute_input":"2021-09-23T12:53:28.615909Z","iopub.status.idle":"2021-09-23T12:54:04.329740Z","shell.execute_reply.started":"2021-09-23T12:53:28.615868Z","shell.execute_reply":"2021-09-23T12:54:04.328653Z"},"trusted":true},"execution_count":9,"outputs":[]}]}