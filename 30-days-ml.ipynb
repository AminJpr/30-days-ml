{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom xgboost import XGBRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T10:32:05.086393Z","iopub.execute_input":"2021-09-29T10:32:05.086803Z","iopub.status.idle":"2021-09-29T10:32:06.159071Z","shell.execute_reply.started":"2021-09-29T10:32:05.086693Z","shell.execute_reply":"2021-09-29T10:32:06.157971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:32:06.161223Z","iopub.execute_input":"2021-09-29T10:32:06.161544Z","iopub.status.idle":"2021-09-29T10:32:10.161967Z","shell.execute_reply.started":"2021-09-29T10:32:06.161511Z","shell.execute_reply":"2021-09-29T10:32:10.160985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:32:10.163497Z","iopub.execute_input":"2021-09-29T10:32:10.163857Z","iopub.status.idle":"2021-09-29T10:32:10.208351Z","shell.execute_reply.started":"2021-09-29T10:32:10.163813Z","shell.execute_reply":"2021-09-29T10:32:10.207371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\ny_test_pred = []\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Scaling Features\n    scaler = preprocessing.StandardScaler()\n    X_train_f[num_col] = scaler.fit_transform(X_train_f[num_col])\n    X_valid_f[num_col] = scaler.transform(X_valid_f[num_col])\n    X_test[num_col] = scaler.transform(X_test[num_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:32:10.211108Z","iopub.execute_input":"2021-09-29T10:32:10.211606Z","iopub.status.idle":"2021-09-29T10:32:36.047883Z","shell.execute_reply.started":"2021-09-29T10:32:10.21156Z","shell.execute_reply":"2021-09-29T10:32:36.045779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting list of list to arraywith column_stack\n#y_test_pred = np.mean(np.column_stack(y_test_pred), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:32:36.049637Z","iopub.execute_input":"2021-09-29T10:32:36.049968Z","iopub.status.idle":"2021-09-29T10:32:36.055628Z","shell.execute_reply.started":"2021-09-29T10:32:36.049925Z","shell.execute_reply":"2021-09-29T10:32:36.054376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\n# Log tranformation\nfor col in num_col:\n    df_train[col] = np.log1p(df_train[col])\n    df_test[col] = np.log1p(df_test[col])\n\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:32:36.057676Z","iopub.execute_input":"2021-09-29T10:32:36.058181Z","iopub.status.idle":"2021-09-29T10:32:59.962596Z","shell.execute_reply.started":"2021-09-29T10:32:36.058138Z","shell.execute_reply":"2021-09-29T10:32:59.961666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1).copy()\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\n# Polynomials\npoly = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n\ntrain_poly = poly.fit_transform(X_train[num_col])\nX_train_poly = pd.DataFrame(train_poly,\n                            columns=[f'poly_{i}' for i in range(train_poly.shape[1])],\n                            index=X_train.index) # using index for cancatenation\nX_train = pd.concat([X_train[cat_col],X_train_poly], axis=1) # To avoid duplicating, we just concat cat_col with poly dataframe\n\ntest_poly = poly.fit_transform(df_test[num_col])\ndf_test_poly = pd.DataFrame(test_poly,\n                            columns=[f'poly_{i}' for i in range(test_poly.shape[1])],\n                            index=X_test.index)\ndf_test = pd.concat([X_test[cat_col],df_test_poly], axis=1)\n\n\n# KFold\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:32:59.964396Z","iopub.execute_input":"2021-09-29T10:32:59.964758Z","iopub.status.idle":"2021-09-29T10:33:36.155243Z","shell.execute_reply.started":"2021-09-29T10:32:59.964716Z","shell.execute_reply":"2021-09-29T10:33:36.154259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target Encoding","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\ny_test_pred = []\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n\n    # Generating X and y for train train_idxd test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    df_train_f = pd.concat([X_train_f,y_train_f], axis=1)\n    \n    for col in cat_col:\n        map_dict = df_train_f.groupby(col).mean().target.to_dict()\n        X_train_f[col] = X_train_f[col].map(map_dict)\n        X_valid_f[col] = X_valid_f[col].map(map_dict)\n        X_test[col] = X_test[col].map(map_dict)\n\n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T10:33:36.157018Z","iopub.execute_input":"2021-09-29T10:33:36.15731Z","iopub.status.idle":"2021-09-29T10:33:48.589708Z","shell.execute_reply.started":"2021-09-29T10:33:36.15727Z","shell.execute_reply":"2021-09-29T10:33:48.588789Z"},"trusted":true},"execution_count":null,"outputs":[]}]}