{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom xgboost import XGBRegressor\n\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2021-09-30T09:26:19.996778Z","iopub.execute_input":"2021-09-30T09:26:19.997090Z","iopub.status.idle":"2021-09-30T09:26:21.842913Z","shell.execute_reply.started":"2021-09-30T09:26:19.997056Z","shell.execute_reply":"2021-09-30T09:26:21.841696Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T09:26:21.844915Z","iopub.execute_input":"2021-09-30T09:26:21.845396Z","iopub.status.idle":"2021-09-30T09:26:25.888407Z","shell.execute_reply.started":"2021-09-30T09:26:21.845335Z","shell.execute_reply":"2021-09-30T09:26:25.886911Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T09:26:25.894674Z","iopub.execute_input":"2021-09-30T09:26:25.895146Z","iopub.status.idle":"2021-09-30T09:26:25.957884Z","shell.execute_reply.started":"2021-09-30T09:26:25.895104Z","shell.execute_reply":"2021-09-30T09:26:25.956834Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model #1 ","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizing Using Optuna\n\ndef objective(trial):\n    \n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 7000),\n        'learning_rate': trial.suggest_loguniform('learning_rate',0.005,0.5),\n        'max_depth': trial.suggest_int('max_depth', 1, 7),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 100.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 100.0),\n        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n        'gamma': trial.suggest_float('gamma', 0.1, 1.0, step=0.1),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree',0.1,1,0.01),\n    }\n    \n    \n    rmse=0\n    kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=42)\n\n    for fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n        # Generating X and y for train and test sets\n        X_train_f = X_train.iloc[train_idx].copy()\n        y_train_f = y_train.iloc[train_idx]\n\n        X_valid_f = X_train.iloc[valid_idx].copy()\n        y_valid_f = y_train.iloc[valid_idx]\n\n        X_test = df_test.copy()\n\n        # Encoding Categorical variables\n        encoder = preprocessing.OrdinalEncoder()\n        X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n        X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n        X_test[cat_col] = encoder.transform(X_test[cat_col])\n\n        # Scaling Features\n        scaler = preprocessing.StandardScaler()\n        X_train_f[num_col] = scaler.fit_transform(X_train_f[num_col])\n        X_valid_f[num_col] = scaler.transform(X_valid_f[num_col])\n        X_test[num_col] = scaler.transform(X_test[num_col])\n\n        # Modeling \n        model = XGBRegressor(**params,\n                             random_state=fold,\n                             tree_method='gpu_hist',\n                             gpu_id=0,\n                             predictor='gpu_predictor')\n    \n        model.fit(X_train_f, y_train_f,\n                  eval_set=[(X_valid_f,y_valid_f)],\n                  early_stopping_rounds=300,\n                  verbose=False)\n        \n        y_pred_f = model.predict(X_valid_f)\n        rmse += metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n        return rmse\n    \n    \n# Optimizing\noptuna.logging.set_verbosity(optuna.logging.WARNING) #stop showing each trial result\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=5)\n\nprint(f'Best score: {study.best_value:.5f}')\nprint(f'Best Params: {study.best_params}')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T10:23:37.005588Z","iopub.execute_input":"2021-09-30T10:23:37.005941Z","iopub.status.idle":"2021-09-30T10:24:36.523515Z","shell.execute_reply.started":"2021-09-30T10:23:37.005910Z","shell.execute_reply":"2021-09-30T10:24:36.521392Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Final Model #1\ny_test_pred = []\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Scaling Features\n    scaler = preprocessing.StandardScaler()\n    X_train_f[num_col] = scaler.fit_transform(X_train_f[num_col])\n    X_valid_f[num_col] = scaler.transform(X_valid_f[num_col])\n    X_test[num_col] = scaler.transform(X_test[num_col])\n    \n    # Modeling\n    model = XGBRegressor(**study.best_params,\n                         random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T10:08:06.933404Z","iopub.execute_input":"2021-09-30T10:08:06.933840Z","iopub.status.idle":"2021-09-30T10:08:56.574641Z","shell.execute_reply.started":"2021-09-30T10:08:06.933795Z","shell.execute_reply":"2021-09-30T10:08:56.571052Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\ny_test_pred = []\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Scaling Features\n    scaler = preprocessing.StandardScaler()\n    X_train_f[num_col] = scaler.fit_transform(X_train_f[num_col])\n    X_valid_f[num_col] = scaler.transform(X_valid_f[num_col])\n    X_test[num_col] = scaler.transform(X_test[num_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:23:33.561205Z","iopub.execute_input":"2021-09-29T12:23:33.561555Z","iopub.status.idle":"2021-09-29T12:23:57.161417Z","shell.execute_reply.started":"2021-09-29T12:23:33.56152Z","shell.execute_reply":"2021-09-29T12:23:57.160459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\n# Log tranformation\nfor col in num_col:\n    df_train[col] = np.log1p(df_train[col])\n    df_test[col] = np.log1p(df_test[col])\n\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:23:57.162802Z","iopub.execute_input":"2021-09-29T12:23:57.163153Z","iopub.status.idle":"2021-09-29T12:24:19.875546Z","shell.execute_reply.started":"2021-09-29T12:23:57.163105Z","shell.execute_reply":"2021-09-29T12:24:19.874591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1).copy()\ny_train = df_train.target\nX_test = df_test\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\n# Polynomials\npoly = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n\ntrain_poly = poly.fit_transform(X_train[num_col])\nX_train_poly = pd.DataFrame(train_poly,\n                            columns=[f'poly_{i}' for i in range(train_poly.shape[1])],\n                            index=X_train.index) # using index for cancatenation\nX_train = pd.concat([X_train[cat_col],X_train_poly], axis=1) # To avoid duplicating, we just concat cat_col with poly dataframe\n\ntest_poly = poly.fit_transform(df_test[num_col])\ndf_test_poly = pd.DataFrame(test_poly,\n                            columns=[f'poly_{i}' for i in range(test_poly.shape[1])],\n                            index=X_test.index)\ndf_test = pd.concat([X_test[cat_col],df_test_poly], axis=1)\n\n\n# KFold\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n    \n    # Generating X and y for train and test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    # Encoding Categorical variables\n    encoder = preprocessing.OrdinalEncoder()\n    X_train_f[cat_col] = encoder.fit_transform(X_train_f[cat_col]) #cat_col\n    X_valid_f[cat_col] = encoder.transform(X_valid_f[cat_col])\n    X_test[cat_col] = encoder.transform(X_test[cat_col])\n    \n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:24:19.876936Z","iopub.execute_input":"2021-09-29T12:24:19.877515Z","iopub.status.idle":"2021-09-29T12:24:52.95471Z","shell.execute_reply.started":"2021-09-29T12:24:19.87747Z","shell.execute_reply":"2021-09-29T12:24:52.953798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/30-days-of-ml/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv', index_col=0)\n\nX_train = df_train.drop('target', axis=1)\ny_train = df_train.target\nX_test = df_test\n\n\nnum_col = [col for col in X_train.columns if 'cat' not in col]\ncat_col = [col for col in X_train.columns if 'cat' in col]\n\ny_test_pred = []\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx,valid_idx) in enumerate(kf.split(X_train)):\n\n    # Generating X and y for train train_idxd test sets\n    X_train_f = X_train.iloc[train_idx].copy()\n    y_train_f = y_train.iloc[train_idx]\n    \n    X_valid_f = X_train.iloc[valid_idx].copy()\n    y_valid_f = y_train.iloc[valid_idx]\n    \n    X_test = df_test.copy()\n    \n    df_train_f = pd.concat([X_train_f,y_train_f], axis=1)\n    \n    for col in cat_col:\n        map_dict = df_train_f.groupby(col).mean().target.to_dict()\n        X_train_f[col] = X_train_f[col].map(map_dict)\n        X_valid_f[col] = X_valid_f[col].map(map_dict)\n        X_test[col] = X_test[col].map(map_dict)\n\n    # Modeling\n    model = XGBRegressor(random_state=fold,\n                         tree_method='gpu_hist',\n                         gpu_id=0,\n                         predictor='gpu_predictor')\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_valid_f)\n    rmse = metrics.mean_squared_error(y_pred_f, y_valid_f, squared=False)\n    print(f'fold-{fold} rmse : {rmse:.5f}')\n    \n    y_test_f = model.predict(X_test)\n    y_test_pred.append(y_test_f)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T12:24:52.95606Z","iopub.execute_input":"2021-09-29T12:24:52.956438Z","iopub.status.idle":"2021-09-29T12:25:03.507683Z","shell.execute_reply.started":"2021-09-29T12:24:52.956402Z","shell.execute_reply":"2021-09-29T12:25:03.506705Z"},"trusted":true},"execution_count":null,"outputs":[]}]}